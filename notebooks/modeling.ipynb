{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Containing Text Classification Modeling Pipelines\n",
    "### ACL22 SRW confidential submission\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from helpers import stratified_kfold, run_gender_model, get_bert_average_across_text_tokens, run_author_attribution_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorship profiling internal vars\n",
    "\n",
    "experiment_name = 'final-refined-set-old' #folder name for saving new outputs\n",
    "\n",
    "write_data_dir = 'acl22-data/final-data/cleaned-data-authorship-profiling/'+experiment_name\n",
    "if not os.path.isdir(write_data_dir):\n",
    "    os.mkdir(write_data_dir)\n",
    "\n",
    "write_model_dir = 'models/final-refined-set-old'\n",
    "if not os.path.isdir(write_model_dir):\n",
    "    os.mkdir(write_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet', 'target'], dtype='object')\n",
      "(372, 2)\n",
      "                                                 tweet  target\n",
      "310  Good to know I actually meant to text that jus...       1\n",
      "110  Yung tawa ko Nakakamiss among us <url><sep>. M...       0 \n",
      "\n",
      "There are 1 NA values \n",
      "\n",
      "There are 37.63% of Female profiles in the dataset. \n",
      "\n",
      "                                                 tweet  target  fold\n",
      "13   daddy got us matching rings <url><sep>. @<user...       0   1.0\n",
      "154  Happening to me <url><sep>. Incredible Congrat...       1   1.0\n",
      "Index(['post', 'target'], dtype='object')\n",
      "(372, 2)\n",
      "                                                  post  target\n",
      "56   <url><sep>. <sep>. This is not true Dont belie...       0\n",
      "175  Say you dont drink cause you get Chosen Weedmi...       1 \n",
      "\n",
      "There are 0 NA values \n",
      "\n",
      "There are 37.63% of Female profiles in the dataset. \n",
      "\n",
      "                                                post  target  fold\n",
      "8  # rembeautyexperience thank you @<user> for th...       0   1.0\n",
      "2  the RIH ISSUE cop these limited edition color ...       0   1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. gender profiling data partitioning\n",
    "\"\"\"\n",
    "\n",
    "#first do twitter\n",
    "\n",
    "data_path = 'acl22-data/intermediate-data/cleaned-data-authorship-profiling/final-refined-set/twitter_celeb_profiling.csv'\n",
    "df = pd.read_csv(data_path, index_col='Unnamed: 0')\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(df.sample(2), '\\n')\n",
    "#Check for missing values\n",
    "missing_df = df.isna().sum()\n",
    "missing_df = pd.DataFrame({'variable' : missing_df.index, 'count' : missing_df.values})\n",
    "missing_df['ratio'] = missing_df['count']/df.shape[0]\n",
    "missing_df = missing_df[missing_df['count'] > 0]\n",
    "print('There are', len(missing_df), 'NA values \\n')\n",
    "#missing_df.sort_values(by=['ratio'], inplace=True)\n",
    "#missing_df.plot(kind='barh', x='variable', y='ratio', title='% rows of missing values', sort_columns=True)\n",
    "\n",
    "df['target'][df['target']=='F'] = 0\n",
    "df['target'][df['target']=='M'] = 1\n",
    "print(f\"There are {str(len(df['target'][df['target']==0])/len(df['target'])*100)[0:5]}% of Female profiles in the dataset. \\n\")\n",
    "\n",
    "df_modeling = stratified_kfold(df, 5)\n",
    "print(df_modeling.sample(2))\n",
    "df_modeling.to_csv(write_data_dir+'/twitter_celeb_profiling_folded.csv')\n",
    "\n",
    "\n",
    "\n",
    "#second do instagram/twitter mixed\n",
    "\n",
    "data_path = 'acl22-data/intermediate-data/cleaned-data-authorship-profiling/final-refined-set/mixed_celeb_profiling.csv'\n",
    "df = pd.read_csv(data_path, index_col='Unnamed: 0')\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(df.sample(2), '\\n')\n",
    "#Check for missing values\n",
    "missing_df = df.isna().sum()\n",
    "missing_df = pd.DataFrame({'variable' : missing_df.index, 'count' : missing_df.values})\n",
    "missing_df['ratio'] = missing_df['count']/df.shape[0]\n",
    "missing_df = missing_df[missing_df['count'] > 0]\n",
    "print('There are', len(missing_df), 'NA values \\n')\n",
    "#missing_df.sort_values(by=['ratio'], inplace=True)\n",
    "#missing_df.plot(kind='barh', x='variable', y='ratio', title='% rows of missing values', sort_columns=True)\n",
    "\n",
    "df['target'][df['target']=='F'] = 0\n",
    "df['target'][df['target']=='M'] = 1\n",
    "print(f\"There are {str(len(df['target'][df['target']==0])/len(df['target'])*100)[0:5]}% of Female profiles in the dataset. \\n\")\n",
    "\n",
    "df_modeling = stratified_kfold(df, 5)\n",
    "print(df_modeling.sample(2))\n",
    "df_modeling.to_csv(write_data_dir+'/mixed_celeb_profiling_folded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector machine model training twitter only dataset:\n",
      "\n",
      "fold  1\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.7972972972972973, 'roc_auc': 0.7950310559006211, 'f1': 0.8314606741573034}\n",
      "SVC(C=1, class_weight='balanced', kernel='sigmoid') \n",
      "\n",
      "fold  2\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.8918918918918919, 'roc_auc': 0.8850931677018634, 'f1': 0.9130434782608695}\n",
      "SVC(C=1, class_weight='balanced', kernel='sigmoid') \n",
      "\n",
      "fold  3\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.8108108108108109, 'roc_auc': 0.8059006211180125, 'f1': 0.8444444444444444}\n",
      "SVC(C=1, class_weight='balanced', kernel='sigmoid') \n",
      "\n",
      "fold  4\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.8513513513513513, 'roc_auc': 0.8524844720496896, 'f1': 0.8764044943820224}\n",
      "SVC(C=1.2, class_weight='balanced', kernel='sigmoid') \n",
      "\n",
      "fold  5\n",
      "n_samples train: 296, n_features train: 10000\n",
      "n_samples val: 76, n_features val: 10000\n",
      "{'accuracy': 0.8552631578947368, 'roc_auc': 0.8184523809523809, 'f1': 0.8932038834951457}\n",
      "SVC(C=1.2, class_weight='balanced', kernel='sigmoid') \n",
      "\n",
      "Logistic regression model training twitter only dataset:\n",
      "\n",
      "fold  1\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.7837837837837838, 'roc_auc': 0.7492236024844721, 'f1': 0.836734693877551}\n",
      "LogisticRegression(class_weight='balanced', penalty='none', solver='saga') \n",
      "\n",
      "fold  2\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.8783783783783784, 'roc_auc': 0.8462732919254659, 'f1': 0.9090909090909092}\n",
      "LogisticRegression(class_weight='balanced', penalty='none', solver='sag') \n",
      "\n",
      "fold  3\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.8108108108108109, 'roc_auc': 0.7779503105590062, 'f1': 0.8571428571428572}\n",
      "LogisticRegression(class_weight='balanced', penalty='none', solver='sag') \n",
      "\n",
      "fold  4\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.8378378378378378, 'roc_auc': 0.8206521739130435, 'f1': 0.8723404255319149}\n",
      "LogisticRegression(class_weight='balanced', penalty='none', solver='saga') \n",
      "\n",
      "fold  5\n",
      "n_samples train: 296, n_features train: 10000\n",
      "n_samples val: 76, n_features val: 10000\n",
      "{'accuracy': 0.868421052631579, 'roc_auc': 0.8288690476190476, 'f1': 0.9038461538461539}\n",
      "LogisticRegression(class_weight='balanced', penalty='none', solver='newton-cg') \n",
      "\n",
      "Support vector machine model training platform-mixed:\n",
      "\n",
      "fold  1\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.7837837837837838, 'roc_auc': 0.7562111801242235, 'f1': 0.8333333333333333}\n",
      "SVC(C=1.2, class_weight='balanced', kernel='linear') \n",
      "\n",
      "fold  2\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.5945945945945946, 'roc_auc': 0.5970496894409938, 'f1': 0.6428571428571428}\n",
      "SVC(C=0.7, class_weight='balanced', kernel='linear') \n",
      "\n",
      "fold  3\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.7567567567567568, 'roc_auc': 0.7624223602484471, 'f1': 0.7906976744186046}\n",
      "SVC(C=0.6, class_weight='balanced', kernel='sigmoid') \n",
      "\n",
      "fold  4\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.7702702702702703, 'roc_auc': 0.7383540372670807, 'f1': 0.8247422680412372}\n",
      "SVC(C=0.8, class_weight='balanced', kernel='linear') \n",
      "\n",
      "fold  5\n",
      "n_samples train: 296, n_features train: 10000\n",
      "n_samples val: 76, n_features val: 10000\n",
      "{'accuracy': 0.7236842105263158, 'roc_auc': 0.6919642857142856, 'f1': 0.787878787878788}\n",
      "SVC(C=0.9, class_weight='balanced', kernel='sigmoid') \n",
      "\n",
      "Logistic regression model training  platform-mixed:\n",
      "\n",
      "fold  1\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.7837837837837838, 'roc_auc': 0.7492236024844721, 'f1': 0.836734693877551}\n",
      "LogisticRegression(class_weight='balanced', penalty='none', solver='newton-cg') \n",
      "\n",
      "fold  2\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.6081081081081081, 'roc_auc': 0.6149068322981366, 'f1': 0.6506024096385542}\n",
      "LogisticRegression(class_weight='balanced', penalty='none') \n",
      "\n",
      "fold  3\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.8108108108108109, 'roc_auc': 0.7709627329192548, 'f1': 0.8599999999999999}\n",
      "LogisticRegression(class_weight='balanced', penalty='none') \n",
      "\n",
      "fold  4\n",
      "n_samples train: 298, n_features train: 10000\n",
      "n_samples val: 74, n_features val: 10000\n",
      "{'accuracy': 0.8108108108108109, 'roc_auc': 0.7849378881987579, 'f1': 0.8541666666666666}\n",
      "LogisticRegression(class_weight='balanced', solver='newton-cg') \n",
      "\n",
      "fold  5\n",
      "n_samples train: 296, n_features train: 10000\n",
      "n_samples val: 76, n_features val: 10000\n",
      "{'accuracy': 0.6842105263157895, 'roc_auc': 0.6160714285714286, 'f1': 0.7777777777777777}\n",
      "LogisticRegression(class_weight='balanced', penalty='none', solver='sag') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. gender profiling modeling part 1: HPO cross val training \n",
    "\"\"\"\n",
    "#results may slightly vary due to random number generator differences\n",
    "\n",
    "# first do twitter model\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/twitter_celeb_profiling_folded.csv', index_col = 'Unnamed: 0')\n",
    "df_modeling\n",
    "\n",
    "# vectorizer settings set to Radivchev et al. (ACL18)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "\n",
    "#SVMs\n",
    "print('Support vector machine model training twitter only dataset:\\n')\n",
    "clf = SVC(class_weight=\"balanced\")\n",
    "param_grid = {\"C\":[0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2], \n",
    "              \"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
    "              \"gamma\":[\"scale\", \"auto\"]\n",
    "             }\n",
    "\n",
    "stats_list = []\n",
    "model_list = []\n",
    "\n",
    "for itr in range(1,6):\n",
    "    #neptune.create_experiment(f'jupyter-pass-SVM-mix-fold{itr}',tags=['Mix', \"Gender Profiling\", \"SVM\"])\n",
    "    print('fold ', itr)\n",
    "    model, stats = run_gender_model(clf,\n",
    "                         param_grid,\n",
    "                         X = df_modeling[['post', 'fold']], \n",
    "                         y = df_modeling[['target', 'fold']],\n",
    "                         k = itr,\n",
    "                         vectorizer = vectorizer)\n",
    "    print(stats)\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    stats_list.append(stats)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    pickle.dump(model, open(write_model_dir+f\"/profiling-SVM-fold{itr}-twitter.pkl\", \"wb\"))\n",
    "    #neptune.log_artifact(f\"modeling/gender-profiling/SVM/SVM-fold{itr}-mix.pkl\")\n",
    "    #eptune.log_metric('Validation-accuracy', stats['accuracy'])\n",
    "    #neptune.log_metric('Validation-roc_auc', stats['roc_auc'])\n",
    "    #neptune.log_metric('Validation-f1', stats['f1'])\n",
    "    #neptune.log_metric('Fold', itr)\n",
    "\n",
    "\n",
    "#LRs\n",
    "print('Logistic regression model training twitter only dataset:\\n')\n",
    "clf = LogisticRegression(class_weight=\"balanced\")\n",
    "param_grid = {\"penalty\":['l1', 'l2', 'elasticnet', 'none'], \n",
    "              \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "             }\n",
    "\n",
    "stats_list = []\n",
    "model_list = []\n",
    "\n",
    "for itr in range(1,6):\n",
    "    #neptune.create_experiment(f'jupyter-pass-SVM-mix-fold{itr}',tags=['Mix', \"Gender Profiling\", \"SVM\"])\n",
    "    print('fold ', itr)\n",
    "    model, stats = run_gender_model(clf,\n",
    "                         param_grid,\n",
    "                         X = df_modeling[['post', 'fold']], \n",
    "                         y = df_modeling[['target', 'fold']],\n",
    "                         k = itr,\n",
    "                         vectorizer = vectorizer)\n",
    "    print(stats)\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    stats_list.append(stats)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    pickle.dump(model, open(write_model_dir+f\"/profiling-LR-fold{itr}-twitter.pkl\", \"wb\"))\n",
    "    #neptune.log_artifact(f\"modeling/gender-profiling/SVM/SVM-fold{itr}-mix.pkl\")\n",
    "    #eptune.log_metric('Validation-accuracy', stats['accuracy'])\n",
    "    #neptune.log_metric('Validation-roc_auc', stats['roc_auc'])\n",
    "    #neptune.log_metric('Validation-f1', stats['f1'])\n",
    "    #neptune.log_metric('Fold', itr)\n",
    "\n",
    "\n",
    "# second do twitter/instagram mixed\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/mixed_celeb_profiling_folded.csv', index_col = 'Unnamed: 0')\n",
    "df_modeling\n",
    "\n",
    "# vectorizer settings set to Radivchev et al. (ACL18)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "\n",
    "#SVMs\n",
    "print('Support vector machine model training platform-mixed:\\n')\n",
    "clf = SVC(class_weight=\"balanced\")\n",
    "param_grid = {\"C\":[0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2], \n",
    "              \"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
    "              \"gamma\":[\"scale\", \"auto\"]\n",
    "             }\n",
    "\n",
    "stats_list = []\n",
    "model_list = []\n",
    "\n",
    "for itr in range(1,6):\n",
    "    #neptune.create_experiment(f'jupyter-pass-SVM-mix-fold{itr}',tags=['Mix', \"Gender Profiling\", \"SVM\"])\n",
    "    print('fold ', itr)\n",
    "    model, stats = run_gender_model(clf,\n",
    "                         param_grid,\n",
    "                         X = df_modeling[['post', 'fold']], \n",
    "                         y = df_modeling[['target', 'fold']],\n",
    "                         k = itr,\n",
    "                         vectorizer = vectorizer)\n",
    "    print(stats)\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    stats_list.append(stats)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    pickle.dump(model, open(write_model_dir+f\"/profiling-SVM-fold{itr}-mix.pkl\", \"wb\"))\n",
    "    #neptune.log_artifact(f\"modeling/gender-profiling/SVM/SVM-fold{itr}-mix.pkl\")\n",
    "    #eptune.log_metric('Validation-accuracy', stats['accuracy'])\n",
    "    #neptune.log_metric('Validation-roc_auc', stats['roc_auc'])\n",
    "    #neptune.log_metric('Validation-f1', stats['f1'])\n",
    "    #neptune.log_metric('Fold', itr)\n",
    "\n",
    "\n",
    "#LRs\n",
    "print('Logistic regression model training  platform-mixed:\\n')\n",
    "clf = LogisticRegression(class_weight=\"balanced\")\n",
    "param_grid = {\"penalty\":['l1', 'l2', 'elasticnet', 'none'], \n",
    "              \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "             }\n",
    "\n",
    "stats_list = []\n",
    "model_list = []\n",
    "\n",
    "for itr in range(1,6):\n",
    "    #neptune.create_experiment(f'jupyter-pass-SVM-mix-fold{itr}',tags=['Mix', \"Gender Profiling\", \"SVM\"])\n",
    "    print('fold ', itr)\n",
    "    model, stats = run_gender_model(clf,\n",
    "                         param_grid,\n",
    "                         X = df_modeling[['post', 'fold']], \n",
    "                         y = df_modeling[['target', 'fold']],\n",
    "                         k = itr,\n",
    "                         vectorizer = vectorizer)\n",
    "    print(stats)\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    stats_list.append(stats)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    pickle.dump(model, open(write_model_dir+f\"/profiling-LR-fold{itr}-mix.pkl\", \"wb\"))\n",
    "    #neptune.log_artifact(f\"modeling/gender-profiling/SVM/SVM-fold{itr}-mix.pkl\")\n",
    "    #eptune.log_metric('Validation-accuracy', stats['accuracy'])\n",
    "    #neptune.log_metric('Validation-roc_auc', stats['roc_auc'])\n",
    "    #neptune.log_metric('Validation-f1', stats['f1'])\n",
    "    #neptune.log_metric('Fold', itr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples train: 372, n_features train: 10000\n",
      "model written to file \n",
      "\n",
      "n_samples train: 372, n_features train: 10000\n",
      "model written to file \n",
      "\n",
      "n_samples train: 372, n_features train: 10000\n",
      "model written to file \n",
      "\n",
      "n_samples train: 372, n_features train: 10000\n",
      "model written to file \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. gender profiling modeling part 2: re-fitting winning fold on entire dataset  \n",
    "\"\"\"\n",
    "\n",
    "# Final model LR mixed instagram + twitter (fold 3)\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/mixed_celeb_profiling_folded.csv', index_col = 'Unnamed: 0')\n",
    "# tfidf featurizer\n",
    "X = df_modeling[['post']]\n",
    "y = df_modeling[['target']]\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "X_train, y_train = [X['post'], np.array(y['target']).astype(int)]    \n",
    "# redefine Xs with tfidf\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_train_tf = vectorizer.transform(X_train)\n",
    "print(\"n_samples train: %d, n_features train: %d\" % X_train_tf.shape)\n",
    "model = pickle.load(open(\"models/final-refined-set-old/profiling-LR-fold3-mix.pkl\", 'rb'))\n",
    "model.fit(X_train_tf, y_train)\n",
    "pickle.dump(model, open(f\"models/final-refined-set-old/final-profiling-LR-mix.pkl\", \"wb\"))\n",
    "print('model written to file \\n')\n",
    "\n",
    "\n",
    "# Final model SVM mixed instagram + twitter (fold 3)\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/mixed_celeb_profiling_folded.csv', index_col = 'Unnamed: 0')\n",
    "# tfidf featurizer\n",
    "X = df_modeling[['post']]\n",
    "y = df_modeling[['target']]\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "X_train, y_train = [X['post'], np.array(y['target']).astype(int)]    \n",
    "# redefine Xs with tfidf\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_train_tf = vectorizer.transform(X_train)\n",
    "print(\"n_samples train: %d, n_features train: %d\" % X_train_tf.shape)\n",
    "model = pickle.load(open(\"models/final-refined-set-old/profiling-SVM-fold3-mix.pkl\", 'rb'))\n",
    "model.fit(X_train_tf, y_train)\n",
    "pickle.dump(model, open(f\"models/final-refined-set-old/final-profiling-SVM-mix.pkl\", \"wb\"))\n",
    "print('model written to file \\n')\n",
    "\n",
    "\n",
    "# Final model LR twitter (fold 2)\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/twitter_celeb_profiling_folded.csv', index_col = 'Unnamed: 0')\n",
    "# tfidf featurizer\n",
    "X = df_modeling[['post']]\n",
    "y = df_modeling[['target']]\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "X_train, y_train = [X['post'], np.array(y['target']).astype(int)]    \n",
    "# redefine Xs with tfidf\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_train_tf = vectorizer.transform(X_train)\n",
    "print(\"n_samples train: %d, n_features train: %d\" % X_train_tf.shape)\n",
    "model = pickle.load(open(\"models/final-refined-set-old/profiling-LR-fold2-twitter.pkl\", 'rb'))\n",
    "model.fit(X_train_tf, y_train)\n",
    "pickle.dump(model, open(f\"models/final-refined-set-old/final-profiling-LR-twitter.pkl\", \"wb\"))\n",
    "print('model written to file \\n')\n",
    "\n",
    "\n",
    "# Final model SVM twitter (fold 2)\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/twitter_celeb_profiling_folded.csv', index_col = 'Unnamed: 0')\n",
    "# tfidf featurizer\n",
    "X = df_modeling[['post']]\n",
    "y = df_modeling[['target']]\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "X_train, y_train = [X['post'], np.array(y['target']).astype(int)]    \n",
    "# redefine Xs with tfidf\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_train_tf = vectorizer.transform(X_train)\n",
    "print(\"n_samples train: %d, n_features train: %d\" % X_train_tf.shape)\n",
    "model = pickle.load(open(\"models/final-refined-set-old/profiling-SVM-fold2-twitter.pkl\", 'rb'))\n",
    "model.fit(X_train_tf, y_train)\n",
    "pickle.dump(model, open(f\"models/final-refined-set-old/final-profiling-SVM-twitter.pkl\", \"wb\"))\n",
    "print('model written to file \\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorship attribution internal vars\n",
    "\n",
    "experiment_name = 'final-refined-set' #folder name for saving new outputs\n",
    "\n",
    "write_data_dir = 'acl22-data/final-data/cleaned-data-authorship-attribution/'+experiment_name\n",
    "if not os.path.isdir(write_data_dir):\n",
    "    os.mkdir(write_data_dir)\n",
    "\n",
    "write_model_dir = 'models/final-refined-set-old'\n",
    "if not os.path.isdir(write_model_dir):\n",
    "    os.mkdir(write_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. authorship attribution data partitioning\n",
    "\"\"\"\n",
    "\n",
    "#first do twitter\n",
    "\n",
    "data_path = 'acl22-data/intermediate-data/cleaned-data-authorship-attribution/final-refined-set/twitter_celeb_attribution.csv'\n",
    "df = pd.read_csv(data_path, index_col='Unnamed: 0')\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(df.sample(2), '\\n')\n",
    "#Check for missing values\n",
    "missing_df = df.isna().sum()\n",
    "missing_df = pd.DataFrame({'variable' : missing_df.index, 'count' : missing_df.values})\n",
    "missing_df['ratio'] = missing_df['count']/df.shape[0]\n",
    "missing_df = missing_df[missing_df['count'] > 0]\n",
    "print('There are', len(missing_df), 'NA values \\n')\n",
    "#missing_df.sort_values(by=['ratio'], inplace=True)\n",
    "#missing_df.plot(kind='barh', x='variable', y='ratio', title='% rows of missing values', sort_columns=True)\n",
    "\n",
    "df_modeling = stratified_kfold(df, 5)\n",
    "print(df_modeling.sample(2))\n",
    "df_modeling.to_csv(write_data_dir+'/twitter_celeb_attribution_folded.csv')\n",
    "\n",
    "\n",
    "\n",
    "#second do instagram/twitter mixed\n",
    "\n",
    "data_path = 'acl22-data/intermediate-data/cleaned-data-authorship-attribution/final-refined-set/mixed_celeb_attribution.csv'\n",
    "df = pd.read_csv(data_path, index_col='Unnamed: 0')\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(df.sample(2), '\\n')\n",
    "#Check for missing values\n",
    "missing_df = df.isna().sum()\n",
    "missing_df = pd.DataFrame({'variable' : missing_df.index, 'count' : missing_df.values})\n",
    "missing_df['ratio'] = missing_df['count']/df.shape[0]\n",
    "missing_df = missing_df[missing_df['count'] > 0]\n",
    "print('There are', len(missing_df), 'NA values \\n')\n",
    "#missing_df.sort_values(by=['ratio'], inplace=True)\n",
    "#missing_df.plot(kind='barh', x='variable', y='ratio', title='% rows of missing values', sort_columns=True)\n",
    "\n",
    "df_modeling = stratified_kfold(df, 5)\n",
    "print(df_modeling.sample(2))\n",
    "df_modeling.to_csv(write_data_dir+'/mixed_celeb_attribution_folded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. authorship attribution modeling part 1: HPO cross val training \n",
    "\"\"\"\n",
    "# results may slightly vary due to random number generator differences\n",
    "\n",
    "# takes a long time to run, not ran for the example code as a result\n",
    "\n",
    "# first do twitter model\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/twitter_celeb_attribution_folded.csv', index_col = 'Unnamed: 0')\n",
    "df_modeling\n",
    "\n",
    "# vectorizer settings set to Radivchev et al. (ACL18)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "\n",
    "#SVMs\n",
    "print('Support vector machine model training twitter only dataset:\\n')\n",
    "clf = SVC(class_weight=\"balanced\")\n",
    "param_grid = {\"C\":[0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2], \n",
    "              \"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
    "              \"gamma\":[\"scale\", \"auto\"]\n",
    "             }\n",
    "\n",
    "stats_list = []\n",
    "model_list = []\n",
    "\n",
    "for itr in range(1,6):\n",
    "    #neptune.create_experiment(f'jupyter-pass-SVM-mix-fold{itr}',tags=['Mix', \"authorship attribution\", \"SVM\"])\n",
    "    print('fold ', itr)\n",
    "    model, stats = run_author_attribution_model(clf,\n",
    "                         param_grid,\n",
    "                         X = df_modeling[['post', 'fold']], \n",
    "                         y = df_modeling[['target', 'fold']],\n",
    "                         k = itr,\n",
    "                         vectorizer = vectorizer)\n",
    "    print(stats)\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    stats_list.append(stats)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    pickle.dump(model, open(write_model_dir+f\"/attribution-SVM-fold{itr}-twitter.pkl\", \"wb\"))\n",
    "    #neptune.log_artifact(f\"modeling/authorship-attribution/SVM/SVM-fold{itr}-mix.pkl\")\n",
    "    #eptune.log_metric('Validation-accuracy', stats['accuracy'])\n",
    "    #neptune.log_metric('Validation-roc_auc', stats['roc_auc'])\n",
    "    #neptune.log_metric('Validation-f1', stats['f1'])\n",
    "    #neptune.log_metric('Fold', itr)\n",
    "\n",
    "\n",
    "#LRs\n",
    "print('Logistic regression model training twitter only dataset:\\n')\n",
    "clf = LogisticRegression(class_weight=\"balanced\")\n",
    "param_grid = {\"penalty\":['l1', 'l2', 'elasticnet', 'none'], \n",
    "              \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "             }\n",
    "\n",
    "stats_list = []\n",
    "model_list = []\n",
    "\n",
    "for itr in range(1,6):\n",
    "    #neptune.create_experiment(f'jupyter-pass-SVM-mix-fold{itr}',tags=['Mix', \"authorship attribution\", \"SVM\"])\n",
    "    print('fold ', itr)\n",
    "    model, stats = run_author_attribution_model(clf,\n",
    "                         param_grid,\n",
    "                         X = df_modeling[['post', 'fold']], \n",
    "                         y = df_modeling[['target', 'fold']],\n",
    "                         k = itr,\n",
    "                         vectorizer = vectorizer)\n",
    "    print(stats)\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    stats_list.append(stats)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    pickle.dump(model, open(write_model_dir+f\"/attribution-LR-fold{itr}-twitter.pkl\", \"wb\"))\n",
    "    #neptune.log_artifact(f\"modeling/authorship-attribution/SVM/SVM-fold{itr}-mix.pkl\")\n",
    "    #eptune.log_metric('Validation-accuracy', stats['accuracy'])\n",
    "    #neptune.log_metric('Validation-roc_auc', stats['roc_auc'])\n",
    "    #neptune.log_metric('Validation-f1', stats['f1'])\n",
    "    #neptune.log_metric('Fold', itr)\n",
    "\n",
    "\n",
    "\n",
    "# second do twitter/instagram mixed\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/mixed_celeb_attribution_folded.csv', index_col = 'Unnamed: 0')\n",
    "df_modeling\n",
    "\n",
    "# vectorizer settings set to Radivchev et al. (ACL18)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "\n",
    "#SVMs\n",
    "print('Support vector machine model training platform-mixed:\\n')\n",
    "clf = SVC(class_weight=\"balanced\")\n",
    "param_grid = {\"C\":[0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2], \n",
    "              \"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
    "              \"gamma\":[\"scale\", \"auto\"]\n",
    "             }\n",
    "\n",
    "stats_list = []\n",
    "model_list = []\n",
    "\n",
    "for itr in range(1,6):\n",
    "    #neptune.create_experiment(f'jupyter-pass-SVM-mix-fold{itr}',tags=['Mix', \"authorship attribution\", \"SVM\"])\n",
    "    print('fold ', itr)\n",
    "    model, stats = run_author_attribution_model(clf,\n",
    "                         param_grid,\n",
    "                         X = df_modeling[['post', 'fold']], \n",
    "                         y = df_modeling[['target', 'fold']],\n",
    "                         k = itr,\n",
    "                         vectorizer = vectorizer)\n",
    "    print(stats)\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    stats_list.append(stats)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    pickle.dump(model, open(write_model_dir+f\"/attribution-SVM-fold{itr}-mix.pkl\", \"wb\"))\n",
    "    #neptune.log_artifact(f\"modeling/authorship-attribution/SVM/SVM-fold{itr}-mix.pkl\")\n",
    "    #eptune.log_metric('Validation-accuracy', stats['accuracy'])\n",
    "    #neptune.log_metric('Validation-roc_auc', stats['roc_auc'])\n",
    "    #neptune.log_metric('Validation-f1', stats['f1'])\n",
    "    #neptune.log_metric('Fold', itr)\n",
    "\n",
    "\n",
    "#LRs\n",
    "print('Logistic regression model training  platform-mixed:\\n')\n",
    "clf = LogisticRegression(class_weight=\"balanced\")\n",
    "param_grid = {\"penalty\":['l1', 'l2', 'elasticnet', 'none'], \n",
    "              \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "             }\n",
    "\n",
    "stats_list = []\n",
    "model_list = []\n",
    "\n",
    "for itr in range(1,6):\n",
    "    #neptune.create_experiment(f'jupyter-pass-SVM-mix-fold{itr}',tags=['Mix', \"authorship attribution\", \"SVM\"])\n",
    "    print('fold ', itr)\n",
    "    model, stats = run_author_attribution_model(clf,\n",
    "                         param_grid,\n",
    "                         X = df_modeling[['post', 'fold']], \n",
    "                         y = df_modeling[['target', 'fold']],\n",
    "                         k = itr,\n",
    "                         vectorizer = vectorizer)\n",
    "    print(stats)\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    stats_list.append(stats)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    pickle.dump(model, open(write_model_dir+f\"/attribution-LR-fold{itr}-mix.pkl\", \"wb\"))\n",
    "    #neptune.log_artifact(f\"modeling/authorship-attribution/SVM/SVM-fold{itr}-mix.pkl\")\n",
    "    #eptune.log_metric('Validation-accuracy', stats['accuracy'])\n",
    "    #neptune.log_metric('Validation-roc_auc', stats['roc_auc'])\n",
    "    #neptune.log_metric('Validation-f1', stats['f1'])\n",
    "    #neptune.log_metric('Fold', itr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6. authorship attribution modeling part 2: re-fitting winning fold on entire dataset  \n",
    "\"\"\"\n",
    "\n",
    "# Final model LR mixed instagram + twitter (fold 1)\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/mixed_celeb_attribution_folded.csv', index_col = 'Unnamed: 0')\n",
    "# tfidf featurizer\n",
    "X = df_modeling[['post']]\n",
    "y = df_modeling[['target']]\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "X_train, y_train = [X['post'], np.array(y['target']).astype(int)]    \n",
    "# redefine Xs with tfidf\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_train_tf = vectorizer.transform(X_train)\n",
    "print(\"n_samples train: %d, n_features train: %d\" % X_train_tf.shape)\n",
    "\n",
    "X_train_tf_nonsparse = pd.DataFrame.sparse.from_spmatrix(X_train_tf)\n",
    "    \n",
    "bert_feats_list = []\n",
    "df_modeling = df_modeling.reset_index(drop=True)\n",
    "for i in range(0,len(X_train_tf_nonsparse)):\n",
    "    bert_feats_list.append(pd.DataFrame(get_bert_average_across_text_tokens(string = df_modeling['post'].loc[i],\n",
    "                                                                            tokenizer = BertTokenizer.from_pretrained('bert-base-cased'),\n",
    "                                                                            model_bert = BertModel.from_pretrained('bert-base-cased'))).T)\n",
    "bert_df = pd.concat(bert_feats_list)    \n",
    "    \n",
    "X_test_both = pd.merge(X_train_tf_nonsparse, bert_df, left_index=True, right_index=True, suffixes=('_tfidf', '_bert'))\n",
    "\n",
    "model = pickle.load(open(\"models/final-refined-set-old/attribution-LR-fold1-mix.pkl\", 'rb'))\n",
    "model.fit(X_test_both, y_train)\n",
    "pickle.dump(model, open(f\"models/final-refined-set-old/final-attribution-LR-mix.pkl\", \"wb\"))\n",
    "print('model written to file \\n')\n",
    "\n",
    "\n",
    "# Final model SVM mixed instagram + twitter (fold 1)\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/mixed_celeb_attribution_folded.csv', index_col = 'Unnamed: 0')\n",
    "# tfidf featurizer\n",
    "X = df_modeling[['post']]\n",
    "y = df_modeling[['target']]\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "X_train, y_train = [X['post'], np.array(y['target']).astype(int)]    \n",
    "# redefine Xs with tfidf\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_train_tf = vectorizer.transform(X_train)\n",
    "print(\"n_samples train: %d, n_features train: %d\" % X_train_tf.shape)\n",
    "\n",
    "X_train_tf_nonsparse = pd.DataFrame.sparse.from_spmatrix(X_train_tf)\n",
    "    \n",
    "bert_feats_list = []\n",
    "df_modeling = df_modeling.reset_index(drop=True)\n",
    "for i in range(0,len(X_train_tf_nonsparse)):\n",
    "    bert_feats_list.append(pd.DataFrame(get_bert_average_across_text_tokens(string = df_modeling['post'].loc[i],\n",
    "                                                                            tokenizer = BertTokenizer.from_pretrained('bert-base-cased'),\n",
    "                                                                            model_bert = BertModel.from_pretrained('bert-base-cased'))).T)\n",
    "bert_df = pd.concat(bert_feats_list)    \n",
    "    \n",
    "X_test_both = pd.merge(X_train_tf_nonsparse, bert_df, left_index=True, right_index=True, suffixes=('_tfidf', '_bert'))\n",
    "\n",
    "model = pickle.load(open(\"models/final-refined-set-old/attribution-SVM-fold1-mix.pkl\", 'rb'))\n",
    "model.fit(X_test_both, y_train)\n",
    "pickle.dump(model, open(f\"models/final-refined-set-old/final-attribution-SVM-mix.pkl\", \"wb\"))\n",
    "print('model written to file \\n')\n",
    "\n",
    "\n",
    "# Final model LR twitter only (fold 1)\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/twitter_celeb_attribution_folded.csv', index_col = 'Unnamed: 0')\n",
    "# tfidf featurizer\n",
    "X = df_modeling[['post']]\n",
    "y = df_modeling[['target']]\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "X_train, y_train = [X['post'], np.array(y['target']).astype(int)]    \n",
    "# redefine Xs with tfidf\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_train_tf = vectorizer.transform(X_train)\n",
    "print(\"n_samples train: %d, n_features train: %d\" % X_train_tf.shape)\n",
    "\n",
    "X_train_tf_nonsparse = pd.DataFrame.sparse.from_spmatrix(X_train_tf)\n",
    "    \n",
    "bert_feats_list = []\n",
    "df_modeling = df_modeling.reset_index(drop=True)\n",
    "for i in range(0,len(X_train_tf_nonsparse)):\n",
    "    bert_feats_list.append(pd.DataFrame(get_bert_average_across_text_tokens(string = df_modeling['post'].loc[i],\n",
    "                                                                            tokenizer = BertTokenizer.from_pretrained('bert-base-cased'),\n",
    "                                                                            model_bert = BertModel.from_pretrained('bert-base-cased'))).T)\n",
    "bert_df = pd.concat(bert_feats_list)    \n",
    "    \n",
    "X_test_both = pd.merge(X_train_tf_nonsparse, bert_df, left_index=True, right_index=True, suffixes=('_tfidf', '_bert'))\n",
    "\n",
    "model = pickle.load(open(\"models/final-refined-set-old/attribution-LR-fold1-twitter.pkl\", 'rb'))\n",
    "model.fit(X_test_both, y_train)\n",
    "pickle.dump(model, open(f\"models/final-refined-set-old/final-attribution-LR-twitter.pkl\", \"wb\"))\n",
    "print('model written to file \\n')\n",
    "\n",
    "\n",
    "# Final model SVM twitter only (fold 1)\n",
    "\n",
    "df_modeling = pd.read_csv(write_data_dir+'/twitter_celeb_attribution_folded.csv', index_col = 'Unnamed: 0')\n",
    "# tfidf featurizer\n",
    "X = df_modeling[['post']]\n",
    "y = df_modeling[['target']]\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    sublinear_tf=True, \n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=10000)\n",
    "X_train, y_train = [X['post'], np.array(y['target']).astype(int)]    \n",
    "# redefine Xs with tfidf\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_train_tf = vectorizer.transform(X_train)\n",
    "print(\"n_samples train: %d, n_features train: %d\" % X_train_tf.shape)\n",
    "\n",
    "X_train_tf_nonsparse = pd.DataFrame.sparse.from_spmatrix(X_train_tf)\n",
    "    \n",
    "bert_feats_list = []\n",
    "df_modeling = df_modeling.reset_index(drop=True)\n",
    "for i in range(0,len(X_train_tf_nonsparse)):\n",
    "    bert_feats_list.append(pd.DataFrame(get_bert_average_across_text_tokens(string = df_modeling['post'].loc[i],\n",
    "                                                                            tokenizer = BertTokenizer.from_pretrained('bert-base-cased'),\n",
    "                                                                            model_bert = BertModel.from_pretrained('bert-base-cased'))).T)\n",
    "bert_df = pd.concat(bert_feats_list)    \n",
    "    \n",
    "X_test_both = pd.merge(X_train_tf_nonsparse, bert_df, left_index=True, right_index=True, suffixes=('_tfidf', '_bert'))\n",
    "\n",
    "model = pickle.load(open(\"models/final-refined-set-old/attribution-SVM-fold1-twitter.pkl\", 'rb'))\n",
    "model.fit(X_test_both, y_train)\n",
    "pickle.dump(model, open(f\"models/final-refined-set-old/final-attribution-SVM-twitter.pkl\", \"wb\"))\n",
    "print('model written to file \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4222c62deee789526b2e6b735eb2f20b12feb76cd92f9c10ded5d55a4a9b08d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('anlp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
